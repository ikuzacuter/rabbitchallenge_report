\documentclass[b5paper,12pt]{jarticle}
\usepackage{amsmath,amssymb}
\usepackage{mathtools}
\usepackage{array}


\begin{document}
\section{非線形回帰}
線形構造（＝直線）でデータの構造をとらえられる場合は限られるため、
非線形な構造をとらえられる回帰が必要。

\subsection{基底展開法}
基底関数と呼ばれる非線形関数$\phi$とパラメータベクトルの線形結合を用いて非線形構造を回帰する手法。
未知パラメータの推定には最小二乗法や最尤法を使用。
\[
  y_i = w_0 \sum_{j=1}^{m}w_j \phi_j (\boldsymbol{x}_i)+\epsilon_i
\]

\subsection{よく使われる基底関数}

多項式関数（1次元）
\[
  \phi_j = x_j
\]
ガウス型基底関数（1次元）
\[
  \phi_j (x) = \exp \{\frac{(x-\mu_j)^2}{2h_j}\}
\]

その他、スプライン関数などがある。

\subsection{未学習}
学習データに対して、十分小さな誤差が得られない状態。
データ構造の複雑さに対してモデルの自由度が小さいときに起こりやすい。

\subsection{過学習}
小さな誤差は得られたが、検証データでの誤差が大きく汎化性能が低いモデル。
学習データ不足、モデルの自由度が高すぎる場合に起こりやすい。

\subsection{正則化法}
過学習防止のために、モデルの複雑さに伴って大きくなる正則化項を加えて誤差最小化を実施する手法。

\subsection{交差検証}
汎化性能を測るための手法。

データを$k$個に分割し、そのうちの$1$個を検証用、残りの$k-1$個を学習用として学習および検証を実施。
同様に、$k$個に分割されたデータのそれぞれが$1$回ずつ検証用となるよう、計$k$回学習および検証を実施する。
最終的に得られた$k$回の精度を平均してCV値（汎化性能）とする。



\end{document}